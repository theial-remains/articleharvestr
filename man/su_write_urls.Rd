% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/store_scraped_data.R
\name{su_write_urls}
\alias{su_write_urls}
\title{Append URLs to CSV for a Specific News Website}
\usage{
su_write_urls(website_url, urls, folder_path = "inst/extdata/scraped_data/")
}
\arguments{
\item{website_url}{A character string representing the URL of the website.}

\item{urls}{A vector of URLs to be added to the CSV file.}

\item{folder_path}{A character string specifying the folder where the CSV is located.}
}
\value{
The full path to the CSV file, or a message indicating the result of the operation.
}
\description{
This function takes a website URL, finds the corresponding CSV file using \code{su_check_csv},
and appends a list of URLs to new rows in the CSV file. Only the "url" column is filled in.
If the file does not exist, it creates a new one.
}
