% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get_url_list.R
\name{gu_remove_duplicates}
\alias{gu_remove_duplicates}
\title{Remove Duplicate URLs Based on Existing CSV for a News Site}
\usage{
gu_remove_duplicates(new_urls, sitemap = NULL)
}
\arguments{
\item{new_urls}{A character vector of newly scraped article URLs.}

\item{sitemap}{(Optional) The sitemap URL used to infer the news site.}
}
\value{
A character vector of URLs that are not already in the CSV.
}
\description{
Loads the site-specific CSV and removes any URLs from the new set that already exist in the CSV.
}
