% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get_url_list.R
\name{gu_remove_duplicates}
\alias{gu_remove_duplicates}
\title{Remove Duplicate URLs Based on Existing CSV}
\usage{
gu_remove_duplicates(new_urls, csv_path = "data/articles.csv")
}
\arguments{
\item{new_urls}{A character vector of newly scraped article URLs.}

\item{csv_path}{The file path to the existing articles CSV.}
}
\value{
A character vector of URLs that are not already in the CSV.
}
\description{
Loads the article CSV and removes any URLs from the new set that already exist in the CSV.
}
